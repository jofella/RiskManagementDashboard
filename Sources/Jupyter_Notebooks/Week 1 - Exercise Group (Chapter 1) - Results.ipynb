{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Group - Chapter 1\n",
    "\n",
    "Below you find exercises for Chapter 1. These exercises will prepare you in particular for the obligatory mid-term tests. The purpose of the prepared code snippets below is to give you some helpful structure for coding by predefining some useful variable names, but you do not need to use these prepared code snippets and prepared variable names if you do not want to. Do not hestitate to use the function `help()` to print the documentation of the functions that you need. If you are stuck, please ask one of the supervisors present.\n",
    "\n",
    "In the shared folder you will find a subfolder `data` containing important time series. You may copy them to your \"*my_materials*\" folder in order to import the data from there if you like.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Topic 1: The Normal Distribution\n",
    "\n",
    "## Step 1: Compute the Log-Returns\n",
    "\n",
    "The executive board of a bank is unhappy with the risk management department and someone suggest to just use the normal distribution instead of all these complicated mathematical models, because they heard that \"log-returns are usually normal distributed\". You get the task to prepare some figures that show why this is not a good idea.\n",
    "\n",
    "**Task 1.1**: Import the time series `DAX_index.csv` containing daily index levels of the German DAX index between 03 January 2000 and 11 October 2024. Write a function that computes the daily log-returns from the index levels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.2**: Draw a plot of the log-returns over time. In a separate plot, draw a histogram of the log-returns using 50 intervals.\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>Interpretation:</summary>\n",
    "    \n",
    "The left plot shows that the log-returns of the DAX are certainly non-iid over time: They exhibit phases with higher volatility and phases with lower volatility. This is called a volatility clustering effect. Therefore, the assumption of iid normally distributed returns should be questioned. The histogram on the right shows a very pronounced center and tails of the unconditional distribution of the log-returns.\n",
    "\n",
    "</details>\n",
    "\n",
    "<img src=\"./Images/Task1_2.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3**: Assume that the log-returns are independent and identically distributed realisations from a normal distribution $N(\\mu, \\sigma^2)$ with mean $\\mu$ and standard deviation $\\sigma$. Compute estimators for $\\mu$ and $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.4**: Plot the density of the $N(\\mu, \\sigma^2)$ distribution using your estimates for $\\mu$ and $\\sigma$ into the histogram from Task 1.2. Use the `density=True` argument to draw a histogram with heights compatible with the density. \n",
    "\n",
    "<details>\n",
    "  <summary>Interpretation:</summary>\n",
    "    \n",
    "The plot confirms once more the observation that the normal distribution is not very well-suited to model the distribution of DAX log-returns: Even though we fitted the parameters of the normal distribution to the returns data, the shape of the density of the normal distribution fails to capture the capture the shape of the distribution of log-returns. Compared to the normal distribution, the log-returns distribution has less mass in the shoulders of the distribution and more mass in the center and in the tails. The heavy tails of the log-returns distribution emphasise the fact that very large daily losses occur relatively much more frequently in reality than predicted by a normal distribution, which is crucial from the perspective of risk management.\n",
    "\n",
    "</details>\n",
    "\n",
    "<img src=\"./Images/Task1_4.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Step 2: Perform a Monte-Carlo Simulation\n",
    "\n",
    "To emphasise the difference between the normal distribution and the distribution of DAX returns, you want to add a Monte-Carlo simulation of normally distributed log-returns.\n",
    "\n",
    "**Task 1.5**: Take your estimators from Task 1.3 and generate $N$ random samples of daily log-returns following the $N(\\mu, \\sigma^2)$ distribution, where $N$ is the length of your DAX returns time series. Use the `numpy` seed 5 for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.6**: Draw a plot of the DAX log-returns over time as in Task 1.2. In a separate plot, draw a plot of your simulated log-returns over time. What can you observe?\n",
    "\n",
    "<details>\n",
    "  <summary>Interpretation:</summary>\n",
    "    \n",
    "This image once more supports the fact that DAX log-returns are non-iid. As opposed to the iid samples from a normal distribution on the right, the DAX log-returns on the left are clearly non-stationary over time. Moreover, the heavier-than-normal tails of the data distribution can be observed here as well: Very high or low log-returns above 0.06 or below -0.06 never occur in 24 years when sampled from a normal distribution, while they occur frequently in real-life times of crisis, i.e. during the financial crisis of 2008 or during the COVID-19 outbreak in early 2020.\n",
    "\n",
    "</details>\n",
    "\n",
    "<img src=\"./Images/Task1_6.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.7**: Plot a histogram of your simulated log-returns from Task 1.5 using 20 intervals. As in Task 1.4, draw the density of the normal distribution with mean $\\mu$ and standard deviation $\\sigma$ into the histogram. Compare your plot to the plot from Task 1.4.\n",
    "\n",
    "<details>\n",
    "  <summary>Interpretation:</summary>\n",
    "    \n",
    "This plot shows how a histogram of the DAX log-returns should look like if the assumption of iid normally distributed returns held true: The histogram of the normally distributed samples very well matches the red Gaussian density. Once compared to the output of Task 1.4, it emphasises the non-applicability of the normal distribution in modelling financial returns.\n",
    "\n",
    "</details>\n",
    "\n",
    "<img src=\"./Images/Task1_7.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.8**: Compute the price process $(S_t)_{t \\in \\{0, \\dots, N\\}}$ corresponding to your simulated log-returns from Task 1.5. As an initial value $S_0$, use the initial index level of the DAX in your DAX time series (i.e. the DAX index level on 03 January 2000). Plot the price process and the DAX index process over time in a common plot.\n",
    "\n",
    "<details>\n",
    "  <summary>Interpretation:</summary>\n",
    "    \n",
    "The below image shows the actual DAX index curve over time in orange next to the synthetic price process with normally distributed returns in blue. This image shows that it is often not possible to identify whether the log-returns of a stock or index are iid normally distributed by just looking at the price process. Both the blue and the orange curve look comparably reasonable, while the log-returns corresponding to both curves clearly behave very differently, see the outputs of Task 1.4, Task 1.6 and Task 1.7.\n",
    "\n",
    "</details>\n",
    "\n",
    "<img src=\"./Images/Task1_8.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Topic 2: Losses and the Loss Operator\n",
    "\n",
    "## Step 1: Compute the Risk Factors\n",
    "\n",
    "Consider a stock portfolio $(V_n)_{n \\in \\{0, \\dots, N\\}}$ with [4, 8, 15, 16, 23] shares of the German stocks [BMW, SAP, Volkswagen, Continental, Siemens]. For the purpose of risk management we chose as risk factors the logarithmic stock prices $Z_{n,i} := \\log(S_{n,i})$.\n",
    "\n",
    "**Task 2.1**: In the file `DAX_companies.csv` you find a time series of the five stocks between 03 January 2000 and 11 October 2024. Import the time series and compute the risk factors $Z_{n} = (Z_{n, 1}, \\dots, Z_{n, 5})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.2**: Now, write a function `f` that computes the portfolio values $V_n = f_n(Z_n)$ from the risk factors as in Section 1.2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.3**: Compute the risk factor changes $X_{n + 1} = Z_{n + 1} - Z_n$ from the risk factors for each $n \\in \\{0, \\dots, N - 1\\}$, where $N$ is the length of your time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Step 2: Calculate the Losses\n",
    "\n",
    " We now want to compute the losses of our portfolio from the risk factor changes. Before you program this, try to answer the following question for yourself. After you thought about it you can click on the question to reveal the answer.\n",
    "\n",
    "<details>\n",
    "  <summary>Why does it make sense to compute the losses from the risk factor changes instead of the time series directly?</summary>\n",
    "\n",
    "  By splitting the calculation of the losses into the risk factor changes and the loss operator we get the advantage that we can now model both separately.\n",
    "  The loss operator depends on the structure of the portfolio and the chosen risk factors. If you now want to incorporate a new risk factor or the structure of your portfolio changes then you only have to adjust the loss operator slightly.\n",
    "  If you want to take a new model for your risk factor changes, then you only have to change these. For example the risk factor changes in this exercise are the log-returns. If you want to do a Monte-Carlo simulation you can now choose any fitting distribution without any thought about the loss operator.\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "**Task 2.4**: Write a function `l(n, x)` for the loss operator $\\ell_{[n]}$ that computes the loss $L_{n + 1}$ from the risk factor change $X_{n + 1}$, see Section 1.2.2. Then, compute the losses $L_{n+1}$ for $n \\in \\{0, \\dots, N-1\\}$ using this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss operator can become a very complicated function. The linearised loss operator tackles this problem, but is not as accurate.\n",
    "\n",
    "**Task 2.5**: Write a function `l_delta(n, x)` for the linearised loss operator $\\ell^\\Delta_{[n]}$ as in Section 1.2.2. Then, compute the linearised losses $L_{n + 1}^\\Delta$ for $n \\in \\{0, \\dots, N - 1\\}$ using this function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.6**: Plot the losses and the linearised losses in a common plot. Are the linearised losses a good approximation to the actual losses?\n",
    "\n",
    "<details>\n",
    "  <summary>Interpretation:</summary>\n",
    "    \n",
    "The below plot shows that the linearised losses (orange) are a quite good approximation to the actual losses (blue), especially in times of low stress in the financial markets. This stems from the fact that the first-order Taylor expansion is quite accurate over the short time interval of one day. Larger deviations between linearised and actual losses occur for losses over longer periods, see Example 1.9.\n",
    "\n",
    "</details>\n",
    "\n",
    "<img src=\"./Images/Task2_6.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Topic 3: Standard Deviation as Risk Measure\n",
    "\n",
    "Consider the time series of DAX index levels $(S_n)_{n \\in \\{0, \\dots, N\\}}$ from Topic 1 and let $(X_{n + 1})_{n \\in \\{0, \\dots, N-1\\}}$ denote the corresponding log-returns. Assume as in Task 1.3 that $(X_{n + 1})_{n \\in \\{0, \\dots, N-1\\}}$ are iid $N(\\mu, \\sigma^2)$ distributed\n",
    "\n",
    "and implement the standard deviation as risk measure for every day as defined in Section 1.4.6 of the Lecture notes.\n",
    "\n",
    "**Task 3.1**: If not already done in Topic 1, repeat the tasks 1.1 and 1.3, i.e. import the time series of DAX index levels, compute the log-returns and estimate $\\mu$ and $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let $L_{n + 1} = -(S_{n + 1} - S_n) = S_n(1 - e^{X_{n + 1}})$ denote the one-day losses.\n",
    "\n",
    "**Task 3.2**: Given the information $\\mathscr{F}_n$ up to time $n$ (see Section 1.4.5), compute the conditional mean $E_n(L_{n+1})$ and conditional variance $\\mathrm{Var}_n(L_{n+1})$. If you are finished you can reveal the answer below to check your results.\n",
    "\n",
    "*Hint:* If $X \\sim N(\\mu, \\sigma^2)$, then $E(e^X) = \\exp(\\mu + \\frac{\\sigma^2}{2})$ and $\\mathrm{Var}(e^X) = (\\exp(\\sigma^2) - 1) \\exp(2 \\mu + \\sigma^2)$.\n",
    "\n",
    "<details>\n",
    "  <summary>Answer:</summary>\n",
    "\n",
    "  We have $L_{n + 1} = S_n(1 - e^{X_{n + 1}}).$ Therefore, $E_n(L_{n+1}) = S_n\\big( 1 - \\exp(\\mu + \\frac{\\sigma^2}{2})\\big)$ and $\\mathrm{Var}_n(L_{n+1}) = S_n^2 (\\exp(\\sigma^2) - 1) \\exp(2 \\mu + \\sigma^2)$.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.3**: Write a function `rho(n, c)` that computes the standard deviation risk measure $\\rho := E_n(L_{n+1}) +  c \\sqrt{\\mathrm{Var}_n(L_{n+1})}$ at time $n$ with some factor $c > 0$, as suggested in Section 1.4.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.4**: Choose some $c > 0$ and compute the risk measures $\\rho$ for each $n \\in \\{0, \\dots, N-1\\}$ using the function `rho`. Plot the losses $L_{n+1}$ and the risk measures against time in a common plot. Repeat this procedure for different values of $c$. Adjust $c$ so that the value of your risk measure is only violated in rare occurences.\n",
    "\n",
    "<details>\n",
    "  <summary>Interpretation:</summary>\n",
    "    \n",
    "The below image uses a value of `c = 1.64` which corresponds to the 95% quantile of the standard normal distribution. Since we assumed that log-returns are iid normally distributed, the obtained standard deviation risk measure is actually equal to the Value-at-Risk risk measure at the level 0.95, as discussed in Topic 4. If one works with different distributions than the normal distribution, it is however not possible anymore to perfectly replicate the VaR risk measure using the standard deviation risk measure with a cleverly chosen constant $c$.\n",
    "\n",
    "</details>\n",
    "\n",
    "<img src=\"./Images/Task3_4.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Topic 4: Value-at-Risk as Risk Measure\n",
    "\n",
    "Consider the setting of Example 1.9, where $(S_n)_{n \\in \\{0, \\dots, N\\}}$ denotes the stock price process of the BMW stock from Topic 2.\n",
    "\n",
    "**Task 4.1**: If not already done in Task 2.1, import the BMW stock prices between 03 January 2000 and 11 October 2024 from the file `DAX_companies.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.2**: Write a function `VaR(s, mu, sigma, alpha)` that computes the Value-at-Risk at level $\\alpha$ for a loss of the form $L_{n+1} = s(1 - e^X)$ as in Example 1.7 using equation (1.5) from the lecture notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.3**: Implement Example 1.9 with two modifications: Instead of $S_n = 100$ as in Example 1.9, use the daily stock prices of the BMW stock from the time series. Moreover, instead of fixing $\\mu$ and $\\sigma^2$ as in the exercise, use estimates of $\\mu$ and $\\sigma$ computed similarly as in Task 1.3. Compute the corresponding one-day Value-at-Risks from Example 1.9 for each $n \\in \\{0, \\dots, N-1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.4**: Plot the VaR and linearised VaR estimates that you obtained in Task 4.3 in a common plot with the actual portfolio losses.\n",
    "\n",
    "<details>\n",
    "  <summary>Interpretation:</summary>\n",
    "    \n",
    "As in Task 2.6, the Value-at-Risk based on the linearised losses deviates only very slightly from the Value-at-Risk of the actual losses since the time increment of one day is very small. Note that, as described in Task 3.4, the Value-at-Risk risk measure and the standard deviation risk measure are equivalent when working with normally distributed log-returns. The reason is that in this case, the one-day loss of the form $L_{n + 1} = s(1 - e^X)$ is log-normally distributed so that the whole loss distribution and hence also any of its quantiles (Value-at-Risks) are completely determined by its mean and standard deviation.\n",
    "\n",
    "</details>\n",
    "\n",
    "<img src=\"./Images/Task4_4.png\" width=\"450\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
